{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kn repository initialized\n",
      "app repository initialized\n",
      "kn <typed_kn_repo.TypedKNRepository object at 0x7fc8fd467880>\n",
      "app <typed_app_repo.TypedAppRepository object at 0x7fc8fd467970>\n"
     ]
    }
   ],
   "source": [
    "from connect import initKNAppDB, initTypedAppDB\n",
    "import pandas as pd\n",
    "\n",
    "kn = initKNAppDB()\n",
    "app = initTypedAppDB()\n",
    "\n",
    "print(\"kn\", kn)\n",
    "print(\"app\", app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내 개인 계정\n",
    "user_id = 'cac185b8-fe16-48f5-ad69-e9216dba1649'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'origin': {'id': '1gPe7NVkj6OAceIwVGmmIQOwQ2E...</td>\n",
       "      <td>93bf71cd-d1df-419b-8b67-385d20ef734d</td>\n",
       "      <td>투자관련</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'origin': {'id': '148tl50oZFnjlL2KVw1xIl1Uy92...</td>\n",
       "      <td>b8199b5c-5ff4-4d9c-9340-b163403b4f2b</td>\n",
       "      <td>막학기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'origin': {'id': '1PVXV1V2nr2RRi-oCxtL5q_0fMv...</td>\n",
       "      <td>aa787ed8-5e8e-40a1-8f5e-7bcfd682cb71</td>\n",
       "      <td>졸업논문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'origin': {'id': '1jcSJREM0VXY7XP9YQ0gTbDZ5Mu...</td>\n",
       "      <td>a801d1ec-e8f7-4e36-ab7c-a3063d2e062b</td>\n",
       "      <td>국문답사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'origin': {'id': '1x1k_TGmT5PhJmMxdhnovFjNpjK...</td>\n",
       "      <td>ad5fc9f9-c22f-4e4e-b1d7-59bfad7092a8</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            metadata  \\\n",
       "0  {'origin': {'id': '1gPe7NVkj6OAceIwVGmmIQOwQ2E...   \n",
       "1  {'origin': {'id': '148tl50oZFnjlL2KVw1xIl1Uy92...   \n",
       "2  {'origin': {'id': '1PVXV1V2nr2RRi-oCxtL5q_0fMv...   \n",
       "3  {'origin': {'id': '1jcSJREM0VXY7XP9YQ0gTbDZ5Mu...   \n",
       "4  {'origin': {'id': '1x1k_TGmT5PhJmMxdhnovFjNpjK...   \n",
       "\n",
       "                                     id title  \n",
       "0  93bf71cd-d1df-419b-8b67-385d20ef734d  투자관련  \n",
       "1  b8199b5c-5ff4-4d9c-9340-b163403b4f2b   막학기  \n",
       "2  aa787ed8-5e8e-40a1-8f5e-7bcfd682cb71  졸업논문  \n",
       "3  a801d1ec-e8f7-4e36-ab7c-a3063d2e062b  국문답사  \n",
       "4  ad5fc9f9-c22f-4e4e-b1d7-59bfad7092a8  test  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "my_document_list = kn.getDocumentByUserId(user_id)\n",
    "my_document_list[0]\n",
    "\n",
    "df = pd.DataFrame(my_document_list, columns=['metadata', 'id', 'title'])\n",
    "df['title'] = df['title'].apply(lambda x: re.sub(r'(\\s+|\\,|\\\\|\\/)', '', x).lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'origin': {'id': '1gPe7NVkj6OAceIwVGmmIQOwQ2E...</td>\n",
       "      <td>93bf71cd-d1df-419b-8b67-385d20ef734d</td>\n",
       "      <td>투자관련</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'origin': {'id': '148tl50oZFnjlL2KVw1xIl1Uy92...</td>\n",
       "      <td>b8199b5c-5ff4-4d9c-9340-b163403b4f2b</td>\n",
       "      <td>막학기</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'origin': {'id': '1PVXV1V2nr2RRi-oCxtL5q_0fMv...</td>\n",
       "      <td>aa787ed8-5e8e-40a1-8f5e-7bcfd682cb71</td>\n",
       "      <td>졸업논문</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'origin': {'id': '1jcSJREM0VXY7XP9YQ0gTbDZ5Mu...</td>\n",
       "      <td>a801d1ec-e8f7-4e36-ab7c-a3063d2e062b</td>\n",
       "      <td>국문답사</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'origin': {'id': '1x1k_TGmT5PhJmMxdhnovFjNpjK...</td>\n",
       "      <td>ad5fc9f9-c22f-4e4e-b1d7-59bfad7092a8</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            metadata  \\\n",
       "0  {'origin': {'id': '1gPe7NVkj6OAceIwVGmmIQOwQ2E...   \n",
       "1  {'origin': {'id': '148tl50oZFnjlL2KVw1xIl1Uy92...   \n",
       "2  {'origin': {'id': '1PVXV1V2nr2RRi-oCxtL5q_0fMv...   \n",
       "3  {'origin': {'id': '1jcSJREM0VXY7XP9YQ0gTbDZ5Mu...   \n",
       "4  {'origin': {'id': '1x1k_TGmT5PhJmMxdhnovFjNpjK...   \n",
       "\n",
       "                                     id title  degree  \n",
       "0  93bf71cd-d1df-419b-8b67-385d20ef734d  투자관련    24.0  \n",
       "1  b8199b5c-5ff4-4d9c-9340-b163403b4f2b   막학기    18.0  \n",
       "2  aa787ed8-5e8e-40a1-8f5e-7bcfd682cb71  졸업논문    19.0  \n",
       "3  a801d1ec-e8f7-4e36-ab7c-a3063d2e062b  국문답사     7.0  \n",
       "4  ad5fc9f9-c22f-4e4e-b1d7-59bfad7092a8  test     1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, document in df.iterrows():\n",
    "    doc_id = document[1]\n",
    "    df.loc[idx, 'degree'] = int(kn.getDocumentDegreeByDocumentId(doc_id)[0][0])\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "doc_to_download = []\n",
    "filename = \"document_to_download.tsv\"\n",
    "\n",
    "os.remove(filename)\n",
    "\n",
    "for _, document in df.iterrows():\n",
    "    metadata = document[0]\n",
    "    doc_id = metadata['origin']['id']\n",
    "    title = document[2]\n",
    "    download_path = f'https://docs.google.com/document/d/{doc_id}/export?format=txt'\n",
    "\n",
    "    doc_to_download.append(download_path)\n",
    "\n",
    "    with open(filename, 'at') as f:\n",
    "        f.write(f'{download_path}\\t{doc_id}\\t{title}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1gPe7NVkj6OAceIwVGmmIQOwQ2EzWe0fKQH7fiUXIOqg 투자관련\n",
      "148tl50oZFnjlL2KVw1xIl1Uy923HN3thyqaLSIzpkhc 막학기\n",
      "1PVXV1V2nr2RRi-oCxtL5q_0fMv66G31DwSWh8vEVIuE 졸업논문\n",
      "1jcSJREM0VXY7XP9YQ0gTbDZ5Mumo93Di8ECCAqlUzno 국문답사\n",
      "1x1k_TGmT5PhJmMxdhnovFjNpjKYaVTlMFowgH-TwlJw test\n",
      "1oUnBHlyWek6VF_dqGL0AdahqKb2g8UXqWgogeth7Ais rollup\n",
      "1pNqAhlVd5LLSlEWwapK0M6Kj3nrocBKhat5UIJmL8Gk geoconnectingstalking\n",
      "1CwmJtsQ5KRaYTtDa0xvE_rqhsAJrvm1yjhrU2FRVLLk 1인기업적합기술\n",
      "1nFG1u_jiZC5fRiCxtryxb1s8zGeS01iWh7FGOC4aGhE js오픈소스프로젝트\n",
      "1-VJIhpu8KiNfk3cbmUYfo3BhNqyXHioBwcuj7bGoNv4 공부할내용들\n",
      "1pJMvAgwuX9H-vkQbAFG6ZUOgSTNyWZdfCAYnQR1XWgM storybook\n",
      "1YgS-p2LWaWt6u6JfJQed-Sk0YlGLotVwI0ZxV9VLbAc vite\n",
      "1_yuT4mgFmBWUXegocl8xJNs3yptIt5rD9Rc2C_XX5RM 프론트도메인주도개발및아키텍쳐\n",
      "1qhTKK1qXDSBbS1ozQ-osRLbSy2AiXPsuFAmxbb47pWs webpack\n",
      "1ClqeTK8m0g7rCIeAVqqRNiKWGjZLdJ8kzrqYxkzQxxU frontendtesting\n",
      "16RpGDG89_zrB6SKyZxYOBJ4ZqREJcmQmGjN5YdRMV7M frontenddevops\n",
      "1o3ge-YviJG4RUE57nrrdq9ypA7epEsoUOnkiXxGibxM 고급개념\n",
      "1GskzyiIRxHuUS37BJ_-dwTVxePEJFmd0BtzK4T_Jx3Q rowlevel(brosweralgo)\n",
      "1f5S3sWgV1OBqOs--OVPHiq27xtk0askGlW_YhWPuce0 디자인팀플레이\n",
      "1HEANVsPghfNH6O-WxAYIhX5DROWS7c1mE1Cl5Fx6oa4 webassembly\n",
      "1CZTaFGhAzI9_BthTAfxKWPIMO_CrrP86mu9C4n11f88 reactnext\n",
      "1sCc_R5WY01ArZP4ozTNmxbUZAD0a6Wyuz-tmbD3SfiI 최적화및상태관리\n",
      "1xe2rWseVaFGkOR2bFCbb7nDno3rjvtMzJGsifbu9-_E 퍼포먼스\n",
      "1D0mV9ebcqjE9Mhnb1DiXOFvzpSV-LH4vAbk103FQ79o ml\n",
      "1nf1YRxgwCSLNdv7xIunqmPFc6RJzR8Ukpox1oau4ydk eletron\n",
      "1AFFt6uZRttE66F0nEqMK5s75kw_-X-v8DW5Cgnv94vI python\n",
      "10q5rp_uIKM87tCVf7o2EHNDzobyIhRq_jI3NgWsva9c gcp\n",
      "1Vwfnf_WJGaivrKsQUrXei8l81zE58D7VzihAbF2hQyk ssr\n",
      "1O1dZ9mklX5POs4_IJG7NxP9QEO429g4SK67fn2mwO9g flutter\n",
      "1m-mCsZyS8kEz7yv7unFei8WiMzWeLEH6VUXMoagnIWI intersection\n",
      "1EwRfyDX8PN5EhdqEa5zwQEf81Y3bs21DDbIiUdPSJE0 back\n",
      "1LM22cKR1fSeABSNAu1EkwbbnPqJvd9lyGE7jp_F5THc react-query\n",
      "1ATEmY7ltLvhf89FgNAa-cs7NmdLjeu9SeeulXpIUk6k kotlin&android\n",
      "1DlHxNCLVAFUsmA1g2wZ1GmBMMwtmnmk5yAQyvbqqKZ4 chromeextension\n",
      "1xBhRMMciJdsGZCBUb6rHDCbBQbVkdAP8_38CtqyJSCE typed주니어로배운것들\n",
      "1_SgfNtRwXZLw9peJDl9BS8vhmX-s0XRo6K68DN2Vy9M vite\n",
      "1iOgugxK8CmeyBEdW4SbfFKJt8E9_23S8RKo1Y3HzFqI 인프라\n",
      "1IbKANX4ikSZ0Og4FA8vj8WDR1zza8LeyIrmE3T7iJoA css\n",
      "1Eagn9DvwKvQSwR-v4-VUdIKsspg05_2fBqIlHvVf5xc javascript\n",
      "1J-Yy0sQTFfCWpy05kYewGt38neCC3Nh05HQMB64fPmA golang\n",
      "1GguIsArmTk6SHKswL0VsxtTe5cU917M2CEXNhiM1NZQ typescript\n",
      "1RhEXvywHZ4boNUZ75eIIRjZQqxWd-_b2uWChvhp5ufk 좋은대표에대해서\n",
      "1OCxiZO2eiX8HL1fPlsSWbT21dl4_57QsPbyvRAv73yU 스타트업\n",
      "1Rc-A_NDGhQoj5ktR-N5KFXZX7XxW1q6gdZMcFzubrcU firebase가왜production으로적합하지않은가\n",
      "1IQCgEldqdwLLSWeKc8GkPAyiaMwQMktbOhc4W_m5MXc 졸업\n",
      "1_V7qa4ZdGgEQRRBF_xqsDFHXNtDkpJs2Zdz1EzmViFA linux\n",
      "18HMkm3ebKAbx8Ppjn_tr1A0Ooma9P5ATUHp8HdwzZQA 벤처경영_졸업보고서\n",
      "1R02Pq8C-9--IzZj_400M6RHS6GZ1MZ5npaO0EtlE6NY tosspofit\n",
      "1tWI5aQt5s97_BYJqQqV_14JT3UawssmkBNTG1AbKaZs nlpelastic\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "bash download_each_doc.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'origin': {'id': '1gPe7NVkj6OAceIwVGmmIQOwQ2E...</td>\n",
       "      <td>93bf71cd-d1df-419b-8b67-385d20ef734d</td>\n",
       "      <td>투자관련</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'origin': {'id': '148tl50oZFnjlL2KVw1xIl1Uy92...</td>\n",
       "      <td>b8199b5c-5ff4-4d9c-9340-b163403b4f2b</td>\n",
       "      <td>막학기</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'origin': {'id': '1PVXV1V2nr2RRi-oCxtL5q_0fMv...</td>\n",
       "      <td>aa787ed8-5e8e-40a1-8f5e-7bcfd682cb71</td>\n",
       "      <td>졸업논문</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'origin': {'id': '1pNqAhlVd5LLSlEWwapK0M6Kj3n...</td>\n",
       "      <td>6b824220-2d46-45a4-ac41-dee16a88cee3</td>\n",
       "      <td>geoconnectingstalking</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'origin': {'id': '1nFG1u_jiZC5fRiCxtryxb1s8zG...</td>\n",
       "      <td>9def5313-a734-45b7-9d14-e2ccd27c93c1</td>\n",
       "      <td>js오픈소스프로젝트</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            metadata  \\\n",
       "0  {'origin': {'id': '1gPe7NVkj6OAceIwVGmmIQOwQ2E...   \n",
       "1  {'origin': {'id': '148tl50oZFnjlL2KVw1xIl1Uy92...   \n",
       "2  {'origin': {'id': '1PVXV1V2nr2RRi-oCxtL5q_0fMv...   \n",
       "6  {'origin': {'id': '1pNqAhlVd5LLSlEWwapK0M6Kj3n...   \n",
       "8  {'origin': {'id': '1nFG1u_jiZC5fRiCxtryxb1s8zG...   \n",
       "\n",
       "                                     id                  title  degree  \n",
       "0  93bf71cd-d1df-419b-8b67-385d20ef734d                   투자관련    24.0  \n",
       "1  b8199b5c-5ff4-4d9c-9340-b163403b4f2b                    막학기    18.0  \n",
       "2  aa787ed8-5e8e-40a1-8f5e-7bcfd682cb71                   졸업논문    19.0  \n",
       "6  6b824220-2d46-45a4-ac41-dee16a88cee3  geoconnectingstalking     4.0  \n",
       "8  9def5313-a734-45b7-9d14-e2ccd27c93c1             js오픈소스프로젝트    10.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, document in df.iterrows():\n",
    "    title = document[2]\n",
    "    path = f'./corpus/raw/{title}.txt'\n",
    "    with open(path, 'rt') as f:\n",
    "        first_line = f.readline()\n",
    "        # 권한 문제로 html이 넘어온 경우 제외\n",
    "        if first_line.startswith('<!doctype html>') | first_line.startswith('<html'):\n",
    "            df.drop(idx, inplace=True)\n",
    "        \n",
    "        # 문서의 작성량 자체가 너무 적으면 제외 (10byte)\n",
    "        if os.path.getsize(path) < 10:\n",
    "            df.drop(idx, inplace=True)\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('document_to_processed.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from soynlp.normalizer import repeat_normalize, emoticon_normalize # https://github.com/lovit/soynlp\n",
    "from pykospacing import Spacing\n",
    "import kss # nltk의 sent_tokenize 보다 한국어에서 더 잘 sentence segmentation을 수행함.\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "class TextProcessor():\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.spacing = Spacing()\n",
    "        self.okt = Okt()\n",
    "        self.text_df = None\n",
    "        self.punctuation_for_sentence = ['.', '?', '!', ',', '\\'', '\\\"']\n",
    "    \n",
    "    def clean_text(self):\n",
    "        text = self.text.strip() # 앞 뒤 공백 제거\n",
    "        text = re.sub(r'(http|www)\\S+', '', text) # url 주소 제거\n",
    "\n",
    "        \n",
    "        remove_punctuation = \"\\n|\" + \"\\\\\" + \"|\\\\\".join([c for c in string.punctuation if c not in self.punctuation_for_sentence])\n",
    "        text = re.sub(remove_punctuation, '', text) # \\n 이스케이프 문자와 기타 sentence segmentation에 불필요한 특수 문자 제거\n",
    "\n",
    "        text = re.sub(r'[a-zA-Z0-9]+', '', text) # 영어, 숫자 제거\n",
    "        text = re.sub(r'\\s+', ' ', text) # 다중 공백을 하나의 공백으로\n",
    "\n",
    "        self.text = text\n",
    "\n",
    "        return self\n",
    "\n",
    "    def normalize_text(self):\n",
    "        self.text = repeat_normalize(emoticon_normalize(self.text))\n",
    "        return self\n",
    "\n",
    "    def spacing_text(self):\n",
    "        self.text = self.spacing(self.text)\n",
    "        return self\n",
    "\n",
    "    def sentence_segmentation(self):\n",
    "        sentences = kss.split_sentences(self.text)\n",
    "        self.text_df = pd.DataFrame(sentences, columns=['sentence'])\n",
    "        return self\n",
    "\n",
    "    def after_clean_text(self):\n",
    "        # sentence segmentation이 끝났으므로 제거하지 못한 구두점 제거\n",
    "        remove_punctuation_for_sentence = \"\\\\\" + \"|\\\\\".join([c for c in self.punctuation_for_sentence])\n",
    "        self.text_df['sentence'] = self.text_df['sentence'].apply(lambda sent: re.sub(remove_punctuation_for_sentence, '', sent))\n",
    "        return self\n",
    "    \n",
    "    def tokenize_text(self):\n",
    "        def pick_noun_and_adjective(pos_tagged):\n",
    "            if pos_tagged[1] == 'Noun' and len(pos_tagged[0]) > 1:\n",
    "                return True\n",
    "            elif pos_tagged[1] == 'Adjective' and len(pos_tagged[0]) > 1:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        self.text_df['tokenized'] = self.text_df['sentence'].apply(lambda sent: list(filter(pick_noun_and_adjective, self.okt.pos(sent, norm=True, stem=True))))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def delete_stopword(self):\n",
    "        ko_stopwords = []\n",
    "        with open('ko_stopword.txt', 'rt') as f:\n",
    "            lines = f.read().splitlines()\n",
    "            for word in lines:\n",
    "                ko_stopwords.append(word)\n",
    "\n",
    "        for morphs in self.text_df['tokenized']:\n",
    "            for morph in morphs:\n",
    "                if morph in ko_stopwords:\n",
    "                    morphs.remove(morph)\n",
    "            self.text_df['tokenized'] = self.text_df['tokenized'].apply(lambda morphs: morphs)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def drop_empty_sentence(self):\n",
    "        # 불용어 처리 결과 문장이 없어진 경우는 row drop\n",
    "        for row in self.text_df.iterrows():\n",
    "            index, series = row[0], row[1]\n",
    "            if len(series['tokenized']) == 0:\n",
    "                self.text_df.drop(index, inplace=True)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, document in df.iterrows():\n",
    "    title = document[2]\n",
    "    text = ''\n",
    "\n",
    "    with open(f'./corpus/raw/{title}.txt', 'rt', encoding=\"utf-8-sig\") as f:\n",
    "        for line in f:\n",
    "            text += line\n",
    "\n",
    "    processor = TextProcessor(text)\n",
    "\n",
    "    normalized = processor.clean_text().normalize_text().spacing_text()\n",
    "\n",
    "    tokenized_text_df = normalized.sentence_segmentation().after_clean_text().tokenize_text().delete_stopword().drop_empty_sentence().text_df\n",
    "\n",
    "    tokenized_text_df.to_csv(f'./corpus/pos_restrict/{title}.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## textRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('단어', 'Noun'), ('있다', 'Adjective'), ('사용', 'Noun'), ('검색', 'Noun'), ('관계', 'Noun')]\n",
      "{('단어', 'Noun'): 0, ('있다', 'Adjective'): 1, ('사용', 'Noun'): 2, ('검색', 'Noun'): 3, ('관계', 'Noun'): 4, ('주변', 'Noun'): 5, ('알고리즘', 'Noun'): 6, ('방법', 'Noun'): 7, ('활용', 'Noun'): 8, ('러닝', 'Noun'): 9, ('처리', 'Noun'): 10, ('없다', 'Adjective'): 11, ('효율', 'Noun'): 12, ('문장', 'Noun'): 13, ('순서', 'Noun'): 14, ('특정', 'Noun'): 15, ('차원', 'Noun'): 16, ('사이', 'Noun'): 17, ('관계성', 'Noun'): 18, ('통해', 'Noun'): 19, ('커리큘럼', 'Noun'): 20, ('벡터', 'Noun'): 21, ('선형', 'Noun'): 22, ('좋다', 'Adjective'): 23, ('생각', 'Noun'): 24, ('하나', 'Noun'): 25, ('강의', 'Noun'): 26, ('자연어', 'Noun'): 27, ('엔진', 'Noun'): 28, ('요소', 'Noun'): 29, ('기능', 'Noun'): 30, ('적임', 'Noun'): 31, ('이나', 'Noun'): 32, ('성능', 'Noun'): 33, ('문서', 'Noun'): 34, ('어떻다', 'Adjective'): 35, ('간의', 'Noun'): 36, ('같다', 'Adjective'): 37, ('타깃', 'Noun'): 38, ('서로', 'Noun'): 39, ('미적', 'Noun'): 40, ('문법', 'Noun'): 41, ('궁극', 'Noun'): 42, ('거임', 'Noun'): 43, ('유사', 'Noun'): 44, ('추천', 'Noun'): 45}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "tokenized_doc = pd.read_csv(\"./corpus/pos_restrict/ml.tsv\", sep='\\t', header=[0])\n",
    "tokenized_doc_series = tokenized_doc['tokenized'].apply(eval)\n",
    "\n",
    "class WordIndexer():\n",
    "    def __init__(self, tokenized_doc_series):\n",
    "        self.tokenized_doc_series = tokenized_doc_series\n",
    "        self.tokens = []\n",
    "        self.word_count = defaultdict(int)\n",
    "        self.idx_to_vocab = []\n",
    "        self.vocab_to_idx = {}\n",
    "\n",
    "    def get_nouns_tokens(self):\n",
    "        for _, document in self.tokenized_doc_series.iteritems():\n",
    "            self.tokens.append(document)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def word_counting(self):\n",
    "        for noun in [token for sent in self.tokens for token in sent]: # flatten tokens for iterate\n",
    "            if noun in self.word_count:\n",
    "                self.word_count[noun] += 1\n",
    "            else:\n",
    "                self.word_count[noun] = 1\n",
    "        return self\n",
    "\n",
    "    def mapping_vocab_to_id(self, min_count = 2):\n",
    "        threshold_word_count = {word: count for word, count in self.word_count.items() if count >= min_count}\n",
    "        self.idx_to_vocab = [w for w, _ in sorted(threshold_word_count.items(), key=lambda x:-x[1])]\n",
    "        self.vocab_to_idx = {vocab:idx for idx, vocab in enumerate(self.idx_to_vocab)}\n",
    "        return self.idx_to_vocab, self.vocab_to_idx\n",
    "\n",
    "word_indexer = WordIndexer(tokenized_doc_series)\n",
    "\n",
    "idx_to_vocab, vocab_to_idx = word_indexer.get_nouns_tokens().word_counting().mapping_vocab_to_id()\n",
    "\n",
    "print(idx_to_vocab[:5])\n",
    "print(vocab_to_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<46x46 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 385 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class CooccurMatrix():\n",
    "    def __init__(self, tokens, vocab_to_idx, window = 5):\n",
    "        self.tokens = tokens\n",
    "        self.vocab_to_idx = vocab_to_idx\n",
    "        self.window = window\n",
    "        self.cooccurrence_matrix = None\n",
    "    \n",
    "    def dict_to_mat(self, d, n_rows, n_cols):\n",
    "        rows, cols, data = [], [], []\n",
    "        for (i, j), v in d.items():\n",
    "            rows.append(i) \n",
    "            cols.append(j) \n",
    "            data.append(v) \n",
    "        return csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))\n",
    "\n",
    "    def create_co_occurrence_matrix(self):\n",
    "        counter = defaultdict(int)\n",
    "        for _, tokens_i in enumerate(self.tokens):\n",
    "            vocabs = [self.vocab_to_idx[w] for w in tokens_i if w in self.vocab_to_idx]\n",
    "            n = len(vocabs)\n",
    "            for i, v in enumerate(vocabs): \n",
    "                if self.window <= 0:\n",
    "                    begin_index, end_index = 0, n\n",
    "                else:\n",
    "                    begin_index = max(0, i - self.window) \n",
    "                    end_index = min(i + self.window, n) \n",
    "                for j in range(begin_index, end_index): \n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    counter[(v, vocabs[j])] += 1\n",
    "                    counter[(vocabs[j], v)] += 1\n",
    "                \n",
    "        counter = {k:v for k,v in counter.items()}\n",
    "        n_vocabs = len(self.vocab_to_idx)\n",
    "        return self.dict_to_mat(counter, n_vocabs, n_vocabs)\n",
    "\n",
    "\n",
    "C = CooccurMatrix(word_indexer.tokens, word_indexer.vocab_to_idx).create_co_occurrence_matrix()\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/nnq96swn52s8yvg0wjkr7sqw0000gn/T/ipykernel_34690/4062148548.py:4: SparseEfficiencyWarning: Comparing sparse matrices using == is inefficient, try using != instead.\n",
      "  is_matrix_symmetric(C)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_matrix_symmetric(matrix):\n",
    "    return (matrix==matrix.T).toarray().all()\n",
    "\n",
    "is_matrix_symmetric(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('단어', 'Noun'), 15.799525519527279),\n",
       " (('추출', 'Noun'), 4.2487027933104144),\n",
       " (('있다', 'Adjective'), 3.4571654360080495),\n",
       " (('분석', 'Noun'), 2.9014140005551052),\n",
       " (('문서', 'Noun'), 2.880536781130387),\n",
       " (('기반', 'Noun'), 2.7888458051264213),\n",
       " (('한국어', 'Noun'), 2.654256351979765),\n",
       " (('사용', 'Noun'), 2.6013156458118605),\n",
       " (('표현', 'Noun'), 2.525392613862564),\n",
       " (('등장', 'Noun'), 2.336757034648675)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def pagerank(x, damper_factor=0.85, iter_count=30):\n",
    "    A = normalize(x, axis=0, norm='l1')\n",
    "    R = np.ones(A.shape[0]).reshape(-1,1)\n",
    "    bias = (1 - damper_factor) * np.ones(A.shape[0]).reshape(-1,1)\n",
    "\n",
    "    for _ in range(iter_count):\n",
    "        R = damper_factor * (A * R) + bias\n",
    "\n",
    "    return R\n",
    "\n",
    "def get_keywords(C, k = 5):\n",
    "    R = pagerank(C, 0.85, 30).reshape(-1)\n",
    "    idxs = R.argsort()[-k:]\n",
    "    keywords = [(idx_to_vocab[idx], R[idx]) for idx in reversed(idxs)]\n",
    "    return keywords\n",
    "# with open(f\"./corpus/keywords/\", \"wt\", encoding=\"utf-8\") as f:\n",
    "#     for keyword, score in keywords:\n",
    "#         f.write(f\"{keyword} : {score}\\n\")\n",
    "\n",
    "\n",
    "keywords = get_keywords(C, 10)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, document in df.iterrows():\n",
    "    try:\n",
    "        title = document[2]\n",
    "        degree = document[3]\n",
    "\n",
    "        tokenized_doc = pd.read_csv(f\"./corpus/pos_restrict/{title}.tsv\", sep='\\t', header=[0])\n",
    "        tokenized_doc_series = tokenized_doc['tokenized'].apply(eval)\n",
    "\n",
    "        word_indexer = WordIndexer(tokenized_doc_series)\n",
    "        idx_to_vocab, vocab_to_idx = word_indexer.get_nouns_tokens().word_counting().mapping_vocab_to_id()\n",
    "\n",
    "        C = CooccurMatrix(word_indexer.tokens, word_indexer.vocab_to_idx).create_co_occurrence_matrix()\n",
    "        keywords = get_keywords(C, 10)\n",
    "\n",
    "        with open(f\"./corpus/all_keywords.tsv\", 'a+t', encoding=\"utf-8\") as f:\n",
    "            for line in keywords:\n",
    "                f.write(f\"{line[0][0]}\\t{line[0][1]}\\t{line[1]}\\t{degree}\\n\")\n",
    "\n",
    "        with open(f\"./corpus/keywords/{title}.tsv\", 'wt', encoding=\"utf-8-sig\") as f:\n",
    "            for line in keywords:\n",
    "                f.write(f\"{line[0][0]}\\t{line[0][1]}\\t{line[1]}\\t{degree}\\n\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    keyword        pos      score  degree\n",
      "0        단어       Noun  15.799526    10.0\n",
      "1        추출       Noun   4.248703    10.0\n",
      "2        있다  Adjective   3.457165    10.0\n",
      "3        분석       Noun   2.901414    10.0\n",
      "4        문서       Noun   2.880537    10.0\n",
      "..      ...        ...        ...     ...\n",
      "214      기반       Noun   2.788846    10.0\n",
      "215     한국어       Noun   2.654256    10.0\n",
      "216      사용       Noun   2.601316    10.0\n",
      "217      표현       Noun   2.525393    10.0\n",
      "218      등장       Noun   2.336757    10.0\n",
      "\n",
      "[219 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>pos</th>\n",
       "      <th>score</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>단어</td>\n",
       "      <td>Noun</td>\n",
       "      <td>15.799526</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>추출</td>\n",
       "      <td>Noun</td>\n",
       "      <td>4.248703</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>있다</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>3.457165</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>분석</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.901414</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>문서</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.880537</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword        pos      score  degree\n",
       "0      단어       Noun  15.799526    10.0\n",
       "1      추출       Noun   4.248703    10.0\n",
       "2      있다  Adjective   3.457165    10.0\n",
       "3      분석       Noun   2.901414    10.0\n",
       "4      문서       Noun   2.880537    10.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keyword_df = pd.read_csv(f\"./corpus/all_keywords.tsv\", sep='\\t', header=None)\n",
    "all_keyword_df.columns = ['keyword',  'pos', 'score', 'degree']\n",
    "\n",
    "print(all_keyword_df)\n",
    "all_keyword_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>pos</th>\n",
       "      <th>score</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가능</td>\n",
       "      <td>Noun</td>\n",
       "      <td>5.505001</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>간단하다</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>0.750848</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>강의</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.096521</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>같다</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>7.894161</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>검색</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.200317</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>혁신</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.814506</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>현대</td>\n",
       "      <td>Noun</td>\n",
       "      <td>0.953227</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>활용</td>\n",
       "      <td>Noun</td>\n",
       "      <td>2.718045</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>회사</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.146093</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>효율</td>\n",
       "      <td>Noun</td>\n",
       "      <td>1.006674</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    keyword        pos     score  degree\n",
       "0        가능       Noun  5.505001    34.0\n",
       "1      간단하다  Adjective  0.750848     2.0\n",
       "2        강의       Noun  1.096521    12.0\n",
       "3        같다  Adjective  7.894161    62.0\n",
       "4        검색       Noun  2.200317    76.0\n",
       "..      ...        ...       ...     ...\n",
       "143      혁신       Noun  1.814506    18.0\n",
       "144      현대       Noun  0.953227    12.0\n",
       "145      활용       Noun  2.718045    97.0\n",
       "146      회사       Noun  1.146093    24.0\n",
       "147      효율       Noun  1.006674    76.0\n",
       "\n",
       "[148 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 중복되는 keyword가 있다면 합산한다.\n",
    "all_keyword_df = all_keyword_df.groupby(['keyword', 'pos']).sum().reset_index()\n",
    "all_keyword_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가능': 187.1700494794745,\n",
       " '간단하다': 1.5016964303136389,\n",
       " '강의': 13.15825424514251,\n",
       " '같다': 489.43796640174577,\n",
       " '검색': 167.2240857854385,\n",
       " '결정': 39.132620158270505,\n",
       " '경로': 15.067992691102566,\n",
       " '경영': 73.87603349257684,\n",
       " '경우': 6.586093093885022,\n",
       " '관계': 118.01224672743103,\n",
       " '관리': 20.964504546166882,\n",
       " '관찰': 8.684210526296713,\n",
       " '교집합': 10.554706622894122,\n",
       " '구조': 2.2887907418288234,\n",
       " '그래프': 16.018690585348253,\n",
       " '그룹': 16.60086920566976,\n",
       " '기반': 241.58398739293472,\n",
       " '기분': 21.973791848328418,\n",
       " '기술': 49.05534153577093,\n",
       " '기업': 17.714347103080346,\n",
       " '내부': 2.516593848333152,\n",
       " '네트워크': 23.17834520549832,\n",
       " '노드': 17.171448106715967,\n",
       " '논문': 17.835305986111578,\n",
       " '다른': 4.294664783163595,\n",
       " '다만': 20.22860623175535,\n",
       " '단어': 3620.8614291859335,\n",
       " '대상': 4.657894736851644,\n",
       " '대장': 10.02130757253294,\n",
       " '대표': 58.846086097584866,\n",
       " '대해': 27.219991613191755,\n",
       " '데이터': 6.580610125816026,\n",
       " '동작': 1.3814855991061838,\n",
       " '등장': 93.470281385947,\n",
       " '디버깅': 24.38449764447976,\n",
       " '라우팅': 17.04288007519746,\n",
       " '라이브러리': 9.963566190486606,\n",
       " '러닝': 84.80659366757894,\n",
       " '렌더': 4.657894736851644,\n",
       " '렌더링': 97.4671905606937,\n",
       " '많다': 20.225583846497113,\n",
       " '메모': 38.271256398061986,\n",
       " '메모리': 16.846524455865087,\n",
       " '메서드': 71.75610799526275,\n",
       " '메인': 3.139985065580574,\n",
       " '모듈': 12.712019463638967,\n",
       " '목적': 25.484958899026733,\n",
       " '목표': 25.076644543216734,\n",
       " '문서': 191.6448664300711,\n",
       " '문학사': 11.376935648909237,\n",
       " '문화': 20.953652078229524,\n",
       " '반환': 163.47324739968062,\n",
       " '방법': 4.865760506579168,\n",
       " '방식': 11.32400718314328,\n",
       " '배열': 14.12711910670442,\n",
       " '버블': 1.6396346597988245,\n",
       " '번만': 2.8596739174334784,\n",
       " '변경': 51.329953400798146,\n",
       " '변수': 14.375793119411952,\n",
       " '변호사': 26.275667048770515,\n",
       " '보통': 29.94594687770647,\n",
       " '부분': 59.24004432498714,\n",
       " '부하': 1.1598571482452504,\n",
       " '분석': 116.0565600222042,\n",
       " '빠르다': 1.1389544165660237,\n",
       " '사업': 33.94027973731783,\n",
       " '사용': 8685.810445738385,\n",
       " '상태': 22.811789081482527,\n",
       " '서비스': 92.4319916942103,\n",
       " '선택': 1.6845937089826002,\n",
       " '설치': 5.519182405306411,\n",
       " '성하다': 1.7744286503284683,\n",
       " '속도': 2.0276323039427395,\n",
       " '스크립트': 12.326904093497753,\n",
       " '스타일': 3.747308288335086,\n",
       " '시드': 51.20921892620075,\n",
       " '시장': 51.577208699278685,\n",
       " '신규': 1.1055643398093915,\n",
       " '실행': 20.021308979857874,\n",
       " '쓰기': 1.9281835356599848,\n",
       " '아니다': 38.6776202152092,\n",
       " '알고리듬': 10.183243268242162,\n",
       " '알고리즘': 81.74721338269566,\n",
       " '어떻다': 1.0,\n",
       " '없다': 475.83657056316423,\n",
       " '연결': 134.7619068926699,\n",
       " '오픈소스': 10.472163380378936,\n",
       " '우리': 1.5161329390191665,\n",
       " '유니언': 11.600430468660523,\n",
       " '유치': 47.56734468267419,\n",
       " '의장': 16.462880639288905,\n",
       " '의존': 11.091725251779263,\n",
       " '이미지': 18.734973181272423,\n",
       " '이벤트': 3.149190977634011,\n",
       " '인스턴스': 17.015504060911283,\n",
       " '인터페이스': 15.69378632815241,\n",
       " '일반': 1.583981588994135,\n",
       " '임베딩': 16.653325759741602,\n",
       " '임원': 19.642063662657268,\n",
       " '있다': 17606.123815337756,\n",
       " '작성': 9.827168093404115,\n",
       " '재무': 19.4252242605196,\n",
       " '재사용': 2.525256599731831,\n",
       " '적용': 32.35243374061606,\n",
       " '점수': 32.881241626323295,\n",
       " '접근': 37.554451242272805,\n",
       " '제공': 31.78032464322724,\n",
       " '제출': 142.0029055650802,\n",
       " '조지': 11.811791931139075,\n",
       " '조직': 18.646721105582703,\n",
       " '졸업': 44.62699450182734,\n",
       " '좋다': 42.99892811074326,\n",
       " '주소': 23.481425264410156,\n",
       " '직원': 17.97636531847527,\n",
       " '집중': 0.9343024771619048,\n",
       " '집합': 32.641511766210776,\n",
       " '차익': 21.55743972942967,\n",
       " '참조': 48.27513082648695,\n",
       " '창업': 17.943351250495105,\n",
       " '처리': 84.34872258724644,\n",
       " '추천': 16.782901819090497,\n",
       " '추출': 169.94811173241658,\n",
       " '출력': 20.24318933949384,\n",
       " '측정': 21.12082140247481,\n",
       " '컴포넌트': 310.43982057440263,\n",
       " '크기': 11.50295223759709,\n",
       " '타입': 150.89305211422177,\n",
       " '통신': 17.48717012624736,\n",
       " '통해': 106.55244239591929,\n",
       " '투자': 526.696494345503,\n",
       " '투자자': 31.21883285237505,\n",
       " '파이썬': 13.194008007409316,\n",
       " '파일': 18.89226094669367,\n",
       " '패키지': 16.633998296315816,\n",
       " '표현': 101.01570455450256,\n",
       " '필요': 24.53970417124023,\n",
       " '필요하다': 33.47057805185058,\n",
       " '학점': 18.789714615495637,\n",
       " '한국': 11.376935648909237,\n",
       " '한국어': 106.1702540791906,\n",
       " '할당': 24.710574929352287,\n",
       " '함수': 468.84205603130624,\n",
       " '해당': 5.318589229773142,\n",
       " '혁신': 32.661114991866434,\n",
       " '현대': 11.438728709074224,\n",
       " '활용': 263.6503609251908,\n",
       " '회사': 27.506238794720062,\n",
       " '효율': 76.50722038750916}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "word_count_dict = {}\n",
    "for index, row in all_keyword_df.iterrows():\n",
    "    word_count_dict[row['keyword']] = row['score'] * row['degree']\n",
    "\n",
    "wc = WordCloud(font_path=\"./NotoSansKR-Regular.otf\",background_color=\"white\", max_font_size=60)\n",
    "cloud = wc.generate_from_frequencies(word_count_dict)\n",
    "\n",
    "# # 생성된 WordCloud를 test.jpg로 보낸다.\n",
    "cloud.to_file('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17606.123815337756 있다\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_most_common_words():\n",
    "    most = 0\n",
    "    most_i = 0\n",
    "    for k, v in word_count_dict.items():\n",
    "        if v > most:\n",
    "            most = v\n",
    "            most_i = k\n",
    "    \n",
    "    print(most, most_i)\n",
    "\n",
    "get_most_common_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "054d12451c88fa6cddb0db320e2c73f4d9b272cf1e754592ad6958aa88348a06"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
